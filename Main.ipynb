{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PL trainer\n",
    "import pytorch_lightning as pl\n",
    "from Dataset import __Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from PL_Trainer import Simple_Trainer\n",
    "from Utils import get_callbacks, init__weighted_random__sampler\n",
    "import torch\n",
    "# for stacking part\n",
    "from xgboost import XGBClassifier\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# utils\n",
    "from Utils import scale_data_without_nan_and_fillna_after\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from scipy.stats import kurtosis, skew\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "# metrics\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "# for clustering features part\n",
    "import category_encoders as ce\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "# visualize\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_bad_columns(df_transaction, df_identity):\n",
    "    # V107 удаляем, там нет дисперсии (одно значение везде)\n",
    "    del df_transaction['V107']\n",
    "    del df_identity['id_27']\n",
    "    del df_identity['id_23']\n",
    "    del df_identity['id_10'] # нет дисперсии (один вид значения)\n",
    "    ## drop cols with > 70% gaps\n",
    "    df_transaction.drop(missing_value_df_transaction.index[-168:].values.tolist(), axis=1, inplace=True)\n",
    "    ## drop cols with > 70% gaps\n",
    "    df_identity.drop(missing_value_df_identity.index[-7:].values.tolist(), axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "def del_skewness_curtosis_in_columns(df_identity):\n",
    "    df_identity['id_01'] = df_identity['id_01'].apply(np.sqrt)\n",
    "    df_identity['id_02'] = df_identity['id_02'].apply(np.sqrt)\n",
    "    df_identity['id_17'] = df_identity['id_17'].apply(np.log10)\n",
    "    df_identity['id_18'] = df_identity['id_18'].apply(np.log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_identity = pd.read_csv('train_identity.csv')\n",
    "df_transaction = pd.read_csv('train_transaction.csv')\n",
    "\n",
    "df_identity_test = pd.read_csv('test_identity.csv')\n",
    "df_transaction_test = pd.read_csv('test_transaction.csv')\n",
    "\n",
    "## test column names need to change\n",
    "df_identity_test.columns = [x.replace('-', '_') for x in df_identity_test.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "categorical_cols_identity = df_identity.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "# check missing\n",
    "percent_missing = df_identity[categorical_cols_identity].isnull().sum() * 100 / len(df_identity[categorical_cols_identity])\n",
    "missing_value_df = pd.DataFrame({'percent_missing': percent_missing})\n",
    "missing_value_df.sort_values('percent_missing', inplace=True)\n",
    "missing_value_df.iloc[:].plot.bar(title='Missing values')\n",
    "categorical_cols_identity + ['id_01', 'id_03', 'id_04', 'id_09', 'id_14', 'id_32', 'TransactionID']\n",
    "## gap filling\n",
    "for col in categorical_cols_identity: ## + id_32\n",
    "    df_identity[col] = df_identity[col].fillna('No Information')\n",
    "    df_identity_test[col] = df_identity_test[col].fillna('No Information')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAFCCAYAAAAKd53gAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAg2ElEQVR4nO3deZwcdb3u8c9DFhLICgQMCZcED5KFQIAJBMKBIEsIonARjLIYCRD0YhDxIBE56LnnClHxnIAXRQhqQCFwWCQXlNWwKUt2tgBhGTCSA8MSCBAwid/7R9XEZtLTM1M9M91ded6vV7+6u6q+Vb+q7n6m5tfVVYoIzMwsXzardAPMzKz9OdzNzHLI4W5mlkMOdzOzHHK4m5nlkMPdzCyHHO5W1SRdLulfy6g/T9Ks9mxTuSR9RdJDlW6H5VvXSjfANk2S6oHtge0j4o2C4UuA3YGhEVEfEV8tZzkRcWE59Wa1ynvuVkkvAV9qfCJpFNCzcs0xyw+Hu1XSNcCXC55PBq4unEDSryX9n/TxNpJuk7RK0luSHpS0WTruXEl/lbRa0rOSDk6Hf1/Sb9LHQySFpMmSXpH0hqTvFiyrp6TZkt6WtEzStyWtKNbwtLvo4ibDbpV0dvp4uqQX0vY8Lel/NjOfxjZ1LRh2n6RTC55PSdvztqQ7Je2YDpek/5T0uqR3JD0uadcWt7ptEhzuVkmPAH0kDZfUBZgE/KbE9N8CVgADgO2A84CQtAvwdWBMRPQGJgD1JeazP7ALcDBwgaTh6fDvAUOAnYBDgRNLzONaYJIkAUjqDxwGzEnHvwD8M9AX+DfgN5IGlphfUZKOJlnPY0jW+0HgunT0YcABwKeAfiTb7822LsPyyeFulda4934o8Azw1xLTrgUGAjtGxNqIeDCSkyOtBzYHRkjqlvbVv1BiPv8WEWsiYimwlKSPH+ALwIUR8XZErAAuLTGPB4EgCXCAY4GHI+JVgIj4r4h4NSL+HhHXA8uBvUvMrzmnAxdFxLKIWAdcCIxO997XAr2BYYDSaVZmWIblkMPdKu0a4HjgKzTpkinix8DzwF2SXpQ0HSAingfOAr4PvC5pjqTtS8znvwsefwD0Sh9vD/ylYFzh449J/6jM4R/fGRwP/LZxvKQvS1qSdiGtAnYFtmlh/YrZEbikYD5vAQIGRcQfgf8LXAa8JukKSX0yLMNyyOFuFRURL5N8sXoEcHML066OiG9FxE7AZ4GzG/vWI+LaiNifJAwD+GGG5qwEBhc836GF6a8Djk33ovcBbgJIn19J0lW0dUT0A54kCeWm3k/vtygY9omCx38BTo+IfgW3nhHxZ4CIuDQi9gJGknTPnNPyatqmwOFu1eAU4NMR8X6piSQdKemf0n7ud0m6Y9ZL2kXSpyVtDnwIrEnHtdUNwHck9Zc0iCScmxURi4EGYBZwZ0SsSkdtSfIHpiFt98kke+7F5tFA0hV1oqQukqYAnyyY5PK0TSPTefWVdFz6eIykfSR1I/kj8SHZ1ttyyOFuFRcRL0TEglZMujNwD/Ae8DDws4i4j6S/fQbwBkmXy7YkX0K21f8m+cL2pXQ5NwIftVBzHXAIyResAETE08BP0ja+BowC/lRiHqeR7HG/SbIH/ueCed1C8l/IHEnvkvwHMDEd3YfkP4S3gZfT+o8dwWObLvliHWbFSfoa8MWIOLDSbTFrK++5m6UkDZQ0TtJm6eGV3wJuqXS7zLLw6QfM/qE78AtgKLCK5GiYn1WyQWZZuVvGzCyH3C1jZpZDDnczsxxqsc9d0i+BI4HXI2LXdNhWwPUk5+GoB74QEW+n475DctzyeuDMiLizpWVss802MWTIkGxrYGa2iVq4cOEbETGg2LgW+9wlHUByXPHVBeH+I+CtiJiR/gS8f0ScK2kEyXG/e5P8lPse4FMRUfKHFXV1dbFgQWsOczYzs0aSFkZEXbFxLXbLRMQDJOezKHQUMDt9PBs4umD4nIj4KCJeIjkPSJaTJZmZWRmy9rlv13j2ufR+23T4ID5+sqUV6bCNSJoqaYGkBQ0NDRmbYWZmxbT3F6rFToxUtN8nIq6IiLqIqBswoGiXkZmZZZT1R0yvSRoYESvTCxC8ng5fwcfPpDcYeDXLAtauXcuKFSv48MMPMzbRqk2PHj0YPHgw3bp1q3RTzHIva7jPJbkk2oz0/taC4ddK+g+SL1R3Bh7LsoAVK1bQu3dvhgwZQnqxG6thEcGbb77JihUrGDp0aKWbY5Z7LXbLSLqO5Ox2u0haIekUklA/VNJykivozACIiKdITpv6NHAHcEZLR8o058MPP2Trrbd2sOeEJLbeemv/J2bWSVrcc4+ILzUz6uBmpv8B8INyGtXIwZ4vfj3NOo9/oWpmlkM1c1bIIdNvb9f51c/4TLvOryPNnDmTqVOnssUWW7Q8cQkLFizg6quv5tJLS133eWNHHHEE1157Lf369Str+WbWOqXyrrXZVTPhXmvWrVtH167ts3lnzpzJiSeeWHa419XVUVdX9MdsJf3+978va7mWf1nDyHUdx90yJdTX1zNs2DAmT57MbrvtxrHHHssHH3zAwoULOfDAA9lrr72YMGECK1euBGD8+PGcd955HHjggVxyySXMnz+f/fbbj9133529996b1atXs379es455xzGjBnDbrvtxi9+8QsA7rvvPsaPH8+xxx7LsGHDOOGEE4gILr30Ul599VUOOuggDjrooGbb2qtXL84991z22msvDjnkEB577DHGjx/PTjvtxNy5czcs48gjjwTg/vvvZ/To0YwePZo99tiD1atXs3LlSg444ABGjx7NrrvuyoMPPgjAkCFDeOONN6ivr2f48OGcdtppjBw5ksMOO4w1a9YAMH/+fHbbbTf23XdfzjnnHHbdteglQ82skzjcW/Dss88ydepUHn/8cfr06cNll13GtGnTuPHGG1m4cCFTpkzhu9/97obpV61axf3338+0adOYNGkSl1xyCUuXLuWee+6hZ8+eXHXVVfTt25f58+czf/58rrzySl566SUAFi9ezMyZM3n66ad58cUX+dOf/sSZZ57J9ttvz7x585g3b16z7Xz//fcZP348CxcupHfv3px//vncfffd3HLLLVxwwQUbTX/xxRdz2WWXsWTJEh588EF69uzJtddey4QJE1iyZAlLly5l9OjRG9UtX76cM844g6eeeop+/fpx0003AXDyySdz+eWX8/DDD9OlS5cyt7qZlcvdMi3YYYcdGDduHAAnnngiF154IU8++SSHHnooAOvXr2fgwIEbpp80aRKQ/FEYOHAgY8aMAaBPnz4A3HXXXTz++OPceOONALzzzjssX76c7t27s/feezN48GAARo8eTX19Pfvvv3+r2tm9e3cOP/xwAEaNGsXmm29Ot27dGDVqFPX19RtNP27cOM4++2xOOOEEjjnmGAYPHsyYMWOYMmUKa9eu5eijjy4a7kOHDt0wfK+99qK+vp5Vq1axevVq9ttvPwCOP/54brvttla128w6hvfcW9D08L3evXszcuRIlixZwpIlS3jiiSe46667NozfcsstgeRHO8UO/YsIfvrTn26of+mllzjssMMA2HzzzTdM16VLF9atW9fqdnbr1m3D8jbbbLMN89pss82Kzmf69OnMmjWLNWvWMHbsWJ555hkOOOAAHnjgAQYNGsRJJ53E1VdfvVFdsTb6al5m1cfh3oJXXnmFhx9+GIDrrruOsWPH0tDQsGHY2rVreeqppzaqGzZsGK+++irz588HYPXq1axbt44JEybw85//nLVr1wLw3HPP8f7775dsQ+/evVm9enV7rhYvvPACo0aN4txzz6Wuro5nnnmGl19+mW233ZbTTjuNU045hUWLFrVqXv3796d379488sgjAMyZM6dd22pmbVcz3TKVOnRx+PDhzJ49m9NPP52dd96ZadOmMWHCBM4880zeeecd1q1bx1lnncXIkSM/Vte9e3euv/56pk2bxpo1a+jZsyf33HMPp556KvX19ey5555EBAMGDOB3v/tdyTZMnTqViRMnMnDgwJL97m0xc+ZM5s2bR5cuXRgxYgQTJ05kzpw5/PjHP6Zbt2706tWr6J57c6666ipOO+00ttxyS8aPH0/fvn3bpZ1mlk1VXCC72MU6li1bxvDhwyvUokR9fT1HHnkkTz75ZEXbUQvee+89evXqBcCMGTNYuXIll1xyyUbTVcPrau2vVg4xzFtdqYt11Myeu1W322+/nYsuuoh169ax44478utf/7rSTTLbpDncSxgyZEjV7bXvs88+fPTRRx8bds011zBq1KgKtSgxadKkDUcKmVnlOdxrzKOPPlrpJphZDajqo2Wq4fsAaz9+Pc06T9WGe48ePXjzzTcdCDnReLGOHj16VLopZpuEqu2WGTx4MCtWrMAXz86PxsvsmVnHq9pw79atmy/HZmaWUdV2y5iZWXYOdzOzHHK4m5nlkMPdzCyHHO5mZjnkcDczyyGHu5lZDjnczcxyyOFuZpZDDnczsxxyuJuZ5ZDD3cwshxzuZmY55HA3M8shh7uZWQ453M3McqiscJf0TUlPSXpS0nWSekjaStLdkpan9/3bq7FmZtY6mcNd0iDgTKAuInYFugBfBKYD90bEzsC96XMzM+tE5XbLdAV6SuoKbAG8ChwFzE7HzwaOLnMZZmbWRpnDPSL+ClwMvAKsBN6JiLuA7SJiZTrNSmDb9miomZm1XjndMv1J9tKHAtsDW0o6sQ31UyUtkLSgoaEhazPMzKyIcrplDgFeioiGiFgL3AzsB7wmaSBAev96seKIuCIi6iKibsCAAWU0w8zMmion3F8BxkraQpKAg4FlwFxgcjrNZODW8ppoZmZt1TVrYUQ8KulGYBGwDlgMXAH0Am6QdArJH4Dj2qOhZmbWepnDHSAivgd8r8ngj0j24s3MrEL8C1UzsxxyuJuZ5ZDD3cwshxzuZmY55HA3M8shh7uZWQ453M3McsjhbmaWQw53M7MccribmeWQw93MLIcc7mZmOeRwNzPLIYe7mVkOOdzNzHLI4W5mlkMOdzOzHHK4m5nlkMPdzCyHyrqGqpnly5Dptzc7rn7GZzqxJVYu77mbmeWQw93MLIcc7mZmOeRwNzPLIYe7mVkOOdzNzHLI4W5mlkMOdzOzHHK4m5nlkMPdzCyHHO5mZjnkcDczyyGHu5lZDjnczcxyqKxwl9RP0o2SnpG0TNK+kraSdLek5el9//ZqrJmZtU65e+6XAHdExDBgd2AZMB24NyJ2Bu5Nn5uZWSfKHO6S+gAHAFcBRMTfImIVcBQwO51sNnB0eU00M7O2KmfPfSegAfiVpMWSZknaEtguIlYCpPfbtkM7zcysDcoJ967AnsDPI2IP4H3a0AUjaaqkBZIWNDQ0lNEMMzNrqpxwXwGsiIhH0+c3koT9a5IGAqT3rxcrjogrIqIuIuoGDBhQRjPMzKypzOEeEf8N/EXSLumgg4GngbnA5HTYZODWslpoZmZt1rXM+mnAbyV1B14ETib5g3GDpFOAV4DjylyGmZm1UVnhHhFLgLoiow4uZ75mZlYe/0LVzCyHHO5mZjnkcDczyyGHu5lZDjnczcxyyOFuZpZDDnczsxwq90dMZtaBhky/vdlx9TM+0+51lh/eczczyyGHu5lZDjnczcxyyOFuZpZDDnczsxxyuJuZ5ZDD3cwshxzuZmY55HA3M8shh7uZWQ453M3McsjhbmaWQz5xmFkb+EReViu8525mlkMOdzOzHHK4m5nlkPvcbZPkPnDLO++5m5nlkMPdzCyHHO5mZjnkPnerae47NyvOe+5mZjnkcDczyyGHu5lZDjnczcxyyOFuZpZDZYe7pC6SFku6LX2+laS7JS1P7/uX30wzM2uL9thz/wawrOD5dODeiNgZuDd9bmZmnaiscJc0GPgMMKtg8FHA7PTxbODocpZhZmZtV+6e+0zg28DfC4ZtFxErAdL7bYsVSpoqaYGkBQ0NDWU2w8zMCmUOd0lHAq9HxMIs9RFxRUTURUTdgAEDsjbDzMyKKOf0A+OAz0k6AugB9JH0G+A1SQMjYqWkgcDr7dFQMzNrvcx77hHxnYgYHBFDgC8Cf4yIE4G5wOR0ssnArWW30szM2qQjjnOfARwqaTlwaPrczMw6UbucFTIi7gPuSx+/CRzcHvM1M7Ns/AtVM7MccribmeWQw93MLIcc7mZmOeRwNzPLIYe7mVkOOdzNzHLI4W5mlkMOdzOzHHK4m5nlkMPdzCyHHO5mZjnkcDczyyGHu5lZDjnczcxyyOFuZpZDDnczsxxyuJuZ5ZDD3cwshxzuZmY55HA3M8shh7uZWQ453M3McsjhbmaWQw53M7MccribmeWQw93MLIcc7mZmOeRwNzPLIYe7mVkOOdzNzHLI4W5mlkMOdzOzHHK4m5nlUOZwl7SDpHmSlkl6StI30uFbSbpb0vL0vn/7NdfMzFqjnD33dcC3ImI4MBY4Q9IIYDpwb0TsDNybPjczs06UOdwjYmVELEofrwaWAYOAo4DZ6WSzgaPLbKOZmbVRu/S5SxoC7AE8CmwXESsh+QMAbNtMzVRJCyQtaGhoaI9mmJlZquxwl9QLuAk4KyLebW1dRFwREXURUTdgwIBym2FmZgXKCndJ3UiC/bcRcXM6+DVJA9PxA4HXy2uimZm1VTlHywi4ClgWEf9RMGouMDl9PBm4NXvzzMwsi65l1I4DTgKekLQkHXYeMAO4QdIpwCvAcWW10MzM2ixzuEfEQ4CaGX1w1vmamVn5/AtVM7MccribmeWQw93MLIcc7mZmOeRwNzPLIYe7mVkOOdzNzHLI4W5mlkMOdzOzHHK4m5nlkMPdzCyHHO5mZjlUzlkhzdrNkOm3NzuufsZnOrElZvngPXczsxxyuJuZ5ZDD3cwshxzuZmY55HA3M8shh7uZWQ453M3McsjhbmaWQw53M7MccribmeWQw93MLIcc7mZmOeRwNzPLIZ8V0orKepZGn93RrDp4z93MLIcc7mZmOeRwNzPLIfe5V0Bn92c3V+c+cLP88p67mVkOec8dHxliZvnjPXczsxzqsHCXdLikZyU9L2l6Ry3HzMw21iHhLqkLcBkwERgBfEnSiI5YlpmZbayj9tz3Bp6PiBcj4m/AHOCoDlqWmZk1oYho/5lKxwKHR8Sp6fOTgH0i4usF00wFpqZPdwGebWZ22wBvZGiG61znusrU1UIb81K3Y0QMKDomItr9BhwHzCp4fhLw04zzWuA617mudupqoY2bQl1HdcusAHYoeD4YeLWDlmVmZk10VLjPB3aWNFRSd+CLwNwOWpaZmTXRIT9iioh1kr4O3Al0AX4ZEU9lnN0VrnOd62qqrhbamPu6DvlC1czMKsu/UDUzyyGHu5lZDlVluEsaIKn4sZtmZtaiqgl3Jb4v6Q3gGeA5SQ2SLqh028zMak3VhDtwFjAOGBMRW0dEf2AfYJykb5YzY0m9OrOuhXn2K7N+gKQ9JI1qbfskbSdpz7Ruu4zL3SpDzT9J+nyW8wplWV5a97ksdW1cRqbtmeW1KzKPTOvX2u0pqWvB416S6rK+Fm1VzvulYB4lt2uW9Sv3M9tkXp33vs7yy6eOuAGLgW2KDB8ALC5z3q+0dx0wCngE+AvJoUr9C8Y9VqJuHXAPcArQrw1tGZHWPQ/8DXgUeAn4NdC3mZrRaRuXpbX3kPxX9AiwZ4llnd9kuc+ly6onOY1Ec3XzGl9Dkl8lPwfMAp4AppWoG5e28SmSP+h3Ay+m23bfEnXHNLl9Hvjvxucd8Npl3Z5tfu3KXL+s2/MrwJvp6zYxrbk3rftSB2zPTO+XMj6zWdcv62c26+co0+u+0XyybMCOuAFPZhlXMM3Zzdy+BbzVAXUPAYcD/YB/ST9In0zHLS5R9wRwJPDb9I12K8mPvHq2sH6PALukj/cGZqePTwNubKZmSbE3ETAWWFpiWYsKHt8OTCxY7p9b8zqR/JBt6/TxFsDjJeoeSwNiX5JzaOyfDt8T+FOJunXAbcAvgV+lt9Xp/S874LXLuj3b/NqVuX5Zt+cTJOcxGQq8W7BNtmvh9cu6PbO+X7J+ZrOuX9bPbNbPUabXvemtmrpl/pZxXKMLgf5A7ya3XpTufspa1ysi7oiIVRFxMfB14A5JY4FSPx5YGxG3RcQJJKdl+C3wBWCFpGtL1PWMiGcBIqLxw0tEXEmyV1DMlhHxaNOBEfEIsGWJZRXaPiL+ULDcniWmXStpUPr4PeD99PFHJD9ma063iHgiIh4GGiLioXR5i1pY3r7p+PnAlIg4GXgjIk6OiCkl6rK+dlm3Z5bXrpz1y7o910fEGxHxEvBeRLyQ1r1WogbK+CxkfL9k/cxmXb+sn9lCbfkcZX3dP6aaLrO3u6R3iwwX0KMV9YuA30XEwo1mIJ3aAXWS1Dci3gGIiHmSPg/cBJTqV1Pjg4hYA9wA3CCpL3B0iboXJP0ryb+Rx5DsRSKpG82/jn+QdDtwNcm/npCc8+fLwB0llrWTpLlpWwdL2iIiPkjHdStR903gLkk3key9/VHSHcA/k+x1NKfwA/mdJuO6N1cUEfMlHQpMS5d1LqXDpFHW1y7r9szy2pWzfpm2J/CKpItIgvIZST8BbgYOAVaWqMu6PbO+X7J+ZjOvX+ODNn5mM32OynjdN5pRLm4kpw0e0My47Vqo26ivvxV1xwNjiwz/H8CVJer+JeP69QN+RPLv2g+A3unwvsXaUVA3Ebgc+H9p7eXAES0s68Amt16N2wM4o4XavsDXgP8EfgqcCwxroeZzwBZFhn8S+HYrt8/2JB+6F1sxbabXroztmem1azKPQW1Yv0zbE+hD8sdgOsle8OfTNl8GDOyg7Znl/ZL1s950/Y5N1+9nLaxf1s9s5s9Rlte96a1qTj/Q0rfIEfFWZ7XFzKzWVVOf+0JgQXrf9LagpWJJXSWdLukOSY9LWirpD5K+mv7722aSmj1hT2cvL0udpC5pG/9d0n5Nxp1fYn6N6/aHtqxb1ros61ZOnaQtJH1b0jmSekj6iqS5kn5UxiGKrXmvZN2ebXqPVeCzUPg+G9dkXKn3Wdb3Z9bldfbr0B7bpdV1G82nWvbcyyXpOmAVMJvkfPKQfPkxGdgqIiY1U9fcfwwiOQJicJUsr811kmaRHHnwGMmhZvdHxNnpuEURsWczy8q6blW/TdK6G0j6zHuS/Iu/jORf388Cn4iIk9p5eZ29PTv7dcj6Puvsus7enp26fhvNpxrDXck36DtS8GVTRDzQQs2zEbFLM+Oei4hPNTNuPfAyBV+akHx5IWBQRBT9AqoCy2tznaTHI2K39HFXkr7FbYAvAY9ExB7tvG5Vv03SuiURMVqSSL5IGxgRkT5f2rjN2nF5nb09O/t1yPo+6+y6zt6enbp+TVXT0TIASPohMAl4GlifDg6gZLgDb0s6DrgpIv6ezmszkkv+vV2i7kXg4Ih4pUhb/lJk+kotL0vdhg9jRKwDpio5ncMfSb5Qak7WdauFbbJBGui/j3QPJ31eam+ns98rtfI6ZH2fdXZdZ2/Pzl6/j2vrN7AdfSO5UPbmGeqGANcDDSS/BHsOeD0dNrRE3RnA7s2MK/Wrys5eXpvrgN+QXKi86fBTSY7dbe91q/ptko6bRXrkQpPhnwQeqqL3Sq28DlnfZ51d19nbs1PXb6PpWzthZ92APxT74LVxHlvT/OGNh2acZ7N1nb289q7riHWr1W1C2lVZbe+VTe116Oi6TWF7tnmGHX0j+eHD88AvgEsbb+04/0Wuq702us51rmtbXdX1uZNcSLsjL6atlifZ5OpqoY2uc53r2lBXdeEeEbMldQcav4F+NiLWtuciXFfRZbnOda7rhLqqC3dJ40mOJ60n+cu0g6TJ0cKhkGZm9g9VF+7AT4DDIj2LnqRPAdcBe7XT/OtdV9Fluc51ruuEuqr7EVPhAfylhhWpO6bU+Ii4eVOrq4U2us51rmufuqaqcc99gaSrgGvS5yeQnF+mJZ9N77cF9iM54B/gIOA+klN7bmp1tdBG17nOde1T93FZDsHpyBuwOclVVW4GbiE553Orf9REcgrPgQXPBwI3b8p1tdBG17nOde1Tt2H61k5YKzeaXJKP5MyXrblMX27raqGNrnOd69qnrvFWNd0ykm6IiC9IeoIih/hEC33uBe6TdCfJl7BBcq3DeZt4XS200XWuc1371AFV9IWqpIERsVLSjsXGR8TLbZjXMSSX6gJ4ICJu2dTraqGNrnOd69qnDqoo3BtJ+mFEnNvSMDMza141XYmp0aFFhk1sqUjSQ+n9aknvFtxWq/iFt3NfVwttdJ3rXNc+dRvNp1r23CV9DfhfJKddfb5gVG/gzxFxQkUaZmZWg6op3PsC/YGLSK5O3mh1+OLYZmZtUjXh3kjSWOCpiFidPu8NjIiIRyvbMjOz2lGN4b4Y2DPShim5nNWCaOVFYc3MrDq/UFUU/MWJ5JqFVXM8vplZLajGcH9R0pmSuqW3b5BcuNfMzFqpGsP9qyQny/krsALYB5ha0RaZmdWYqutzNzOz8lVdX7akHsApwEigR+PwiJhSsUaZmdWYauyWuQb4BDABuB8YDKyuaIvMzGpM1XXLSFocEXsovfqSpG7AnRHx6Uq3zcysVlTjnvva9H6VpF2BvsCQyjXHzKz2VF2fO3CFpP7A+cBcoBdwQWWbZGZWW6quW8bMzMpXdd0ykr4hqY8SsyQtknRYpdtlZlZLqi7cgSkR8S5wGMnVv08GZlS2SWZmtaUaw13p/RHAryJiacEwMzNrhWoM94WS7iIJ9zvTU/7+vcJtMjOrKVX3hWp6it/RwIsRsUrS1sCgiHi8si0zM6sdVXcoZET8XdJrwAhJVdc+M7NaUHXhKemHwCTgaWB9OjiAByrWKDOzGlON3TLPArtFxEeVbouZWa2qxi9UXwS6VboRZma1rOq6ZYAPgCWS7gU27L1HxJmVa5KZWW2pxnCfm97MzCyjqutzNzOz8lXdnruknYGLgBF8/EpMO1WsUWZmNaYav1D9FfBzYB1wEHA1ydWZzMyslaox3HtGxL0kXUYvR8T3AV+FycysDaquWwb4MD0FwXJJXwf+SnJ2SDMza6Wq+0JV0hhgGdAP+HegD/DjiHikku0yM6slVRXukroAMyLinEq3xcysllVNn7ukrhGxHthLks/fbmZWhmrqc38M2BNYDNwq6b+A9xtHRsTNlWqYmVmtqaZwb7QV8CbJETJBchWmABzuZmatVE3hvq2ks4En+UeoN6qeLwbMzGpANYV7F6AXxa+X6nA3M2uDqjlaRtKiiNiz0u0wM8uDqjlahuJ77GZmlkE17blvFRFvVbodZmZ5UDXhbmZm7aeaumXMzKydONzNzHLI4W5mlkMOdzOzHHK4m5nl0P8HmonBAkdAeHsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_cols_identity = df_identity._get_numeric_data().columns\n",
    "percent_missing = df_identity[num_cols_identity].isnull().sum() * 100 / len(df_identity[num_cols_identity])\n",
    "missing_value_df_identity = pd.DataFrame({'percent_missing': percent_missing})\n",
    "missing_value_df_identity.sort_values('percent_missing', inplace=True)\n",
    "missing_value_df_identity.iloc[:].plot.bar(title='Missing values')\n",
    "## only continuous\n",
    "num_cols_identity = ['id_20', 'id_19', 'id_18', 'id_17', 'id_13', 'id_11', 'id_06', 'id_05', 'id_02']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       percent_missing\n",
      "V238         76.053104\n",
      "V220         76.053104\n",
      "V221         76.053104\n",
      "V222         76.053104\n",
      "V227         76.053104\n",
      "...                ...\n",
      "D12          89.041047\n",
      "D14          89.469469\n",
      "D13          89.509263\n",
      "D7           93.409930\n",
      "dist2        93.628374\n",
      "\n",
      "[168 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "percent_missing = df_transaction.isnull().sum() * 100 / len(df_transaction)\n",
    "missing_value_df_transaction = pd.DataFrame({'percent_missing': percent_missing})\n",
    "missing_value_df_transaction.sort_values('percent_missing', inplace=True)\n",
    "print(missing_value_df_transaction[-168:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_12',\n",
       " 'id_15',\n",
       " 'id_16',\n",
       " 'id_28',\n",
       " 'id_29',\n",
       " 'id_30',\n",
       " 'id_31',\n",
       " 'id_33',\n",
       " 'id_34',\n",
       " 'id_35',\n",
       " 'id_36',\n",
       " 'id_37',\n",
       " 'id_38',\n",
       " 'DeviceType',\n",
       " 'DeviceInfo',\n",
       " 'id_01',\n",
       " 'id_03',\n",
       " 'id_04',\n",
       " 'id_09',\n",
       " 'id_14',\n",
       " 'id_32',\n",
       " 'TransactionID']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del_bad_columns(df_transaction, df_identity)\n",
    "del_bad_columns(df_transaction_test, df_identity_test)\n",
    "## identity categorical cols for modelling\n",
    "categorical_cols_identity = df_identity.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "categorical_cols_identity + ['id_01', 'id_03', 'id_04', 'id_09', 'id_14', 'id_32', 'TransactionID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols_transaction = [\n",
    "    'ProductCD', 'card4', 'card6', 'card2', 'card3', 'card5', 'P_emaildomain',\n",
    "    'addr1', 'addr2', 'card1', 'V1', \n",
    "    'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', \n",
    "    'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9','V10', \n",
    "    'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', \n",
    "    'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26',\n",
    "    'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', \n",
    "    'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', \n",
    "    'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', \n",
    "    'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58',\n",
    "    'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66',\n",
    "    'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', \n",
    "    'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', \n",
    "    'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', \n",
    "    'V91', 'V92', 'V93', 'V94', 'V281', 'V282', 'V283', 'V284',\n",
    "    'V286', 'V287', 'V288', 'V289', 'V297', 'V299', 'V300',\n",
    "    'V301', 'V302', 'V303', 'V304', 'V305', 'V98', 'V106', \n",
    "    'V108','V109','V110','V111','V112', 'V113','V114',\n",
    "    'V115','V116','V117','V118', 'V119','V120','V121', \n",
    "    'V122','V123','V124', 'V125', 'V99', 'V104', 'V100', 'V105' \n",
    "]\n",
    "\n",
    "## fillna train / test\n",
    "for col in categorical_cols_transaction:\n",
    "    df_transaction[col] = df_transaction[col].fillna('No Information') \n",
    "    df_transaction_test[col] = df_transaction_test[col].fillna('No Information') \n",
    "## \n",
    "categorical_col__unique_values = {}\n",
    "for col in categorical_cols_transaction:\n",
    "    categorical_col__unique_values[col] = df_transaction[col].unique()\n",
    "##\n",
    "num_cols_transaction = [\n",
    "    'TransactionAmt','dist1', 'V95', 'V96', 'V97', 'V101', 'V102', 'V103', \n",
    "    'V126', 'V127', 'V128', 'V129', 'V130', 'V131', 'V132', 'V133', 'V134',\n",
    "    'V135', 'V136', 'V137', 'V279', 'V280', 'V285', 'V290', 'V291', 'V292', \n",
    "    'V293', 'V294', 'V295', 'V296', 'V298', 'V306', 'V307', 'V308', 'V309', \n",
    "    'V310', 'V311', 'V312', 'V313', 'V314', 'V315', 'V316', 'V317', 'V318', \n",
    "    'V319', 'V320', 'V321', 'C1','C2','C4','C5','C6','C7', 'C8','C9','C10',\n",
    "    'C11', 'C3', 'C12','C13','C14','D1', 'D2','D3','D4','D5', 'D10', 'D11', 'D15'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove skewness / curtosis \n",
    "del_skewness_curtosis_in_columns(df_identity)\n",
    "del_skewness_curtosis_in_columns(df_identity_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       percent_missing\n",
      "id_11         2.256765\n",
      "id_02         2.330257\n",
      "id_17         3.372321\n",
      "id_19         3.407681\n",
      "id_20         3.447200\n",
      "id_06         5.108401\n",
      "id_05         5.108401\n",
      "id_13        11.726165\n",
      "id_18        68.722137\n"
     ]
    }
   ],
   "source": [
    "percent_missing = df_identity[num_cols_identity].isnull().sum() * 100 / len(df_identity[num_cols_identity])\n",
    "missing_value_df = pd.DataFrame({'percent_missing': percent_missing})\n",
    "missing_value_df.sort_values('percent_missing', inplace=True)\n",
    "print(missing_value_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identity\n",
    "## train\n",
    "numerical_col_identity__minmaxscaler = scale_data_without_nan_and_fillna_after(df_identity, num_cols_identity)\n",
    "df_identity = df_identity.fillna(-1)\n",
    "## test\n",
    "scale_data_without_nan_and_fillna_after(df_identity_test, num_cols_identity, numerical_col_identity__minmaxscaler)\n",
    "df_identity_test = df_identity_test.fillna(-1)\n",
    "\n",
    "# Transaction\n",
    "## train\n",
    "numerical_col_transaction__minmaxscaler = scale_data_without_nan_and_fillna_after(df_transaction, num_cols_transaction)\n",
    "df_transaction = df_transaction.fillna(-1)\n",
    "## test\n",
    "scale_data_without_nan_and_fillna_after(df_transaction_test, num_cols_transaction, numerical_col_transaction__minmaxscaler)\n",
    "df_transaction_test = df_transaction_test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "## merge and gap filling\n",
    "df_train = df_transaction.merge(df_identity, how='left', on='TransactionID')\n",
    "for col in categorical_cols_transaction + categorical_cols_identity:\n",
    "    df_train[col] = df_train[col].fillna('No Information')\n",
    "df_train[num_cols_transaction + num_cols_identity] = df_train[num_cols_transaction + num_cols_identity].fillna(-1)\n",
    "Y = df_train['isFraud']\n",
    "# TEST\n",
    "df_prod = df_transaction_test.merge(df_identity_test, how='left', on='TransactionID')\n",
    "for col in categorical_cols_transaction + categorical_cols_identity:\n",
    "    df_prod[col] = df_prod[col].fillna('No Information')\n",
    "df_prod[num_cols_transaction + num_cols_identity] = df_prod[num_cols_transaction + num_cols_identity].fillna(-1)\n",
    "## Full\n",
    "df_train = df_train[num_cols_transaction + num_cols_identity + categorical_cols_transaction + categorical_cols_identity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add clustering features\n",
    "## catboostencoder for categorical\n",
    "## fit df_train, predict df_prod \n",
    "\n",
    "cb_encoder = ce.CatBoostEncoder()\n",
    "data_for_clustering = deepcopy(df_train)\n",
    "data_for_clustering_prod = deepcopy(df_prod)\n",
    "\n",
    "for col in categorical_cols_transaction + categorical_cols_identity:\n",
    "    data_for_clustering[col] = data_for_clustering[col].astype(str)\n",
    "    data_for_clustering_prod[col] = data_for_clustering_prod[col].astype(str)\n",
    "\n",
    "## catboost encoder after label encoding\n",
    "data_for_clustering[categorical_cols_transaction + categorical_cols_identity] = cb_encoder.fit_transform(data_for_clustering[categorical_cols_transaction + categorical_cols_identity], Y)\n",
    "data_for_clustering_prod[categorical_cols_transaction + categorical_cols_identity] = cb_encoder.transform(data_for_clustering_prod[categorical_cols_transaction + categorical_cols_identity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## find the optimal number of clusters\n",
    "cost = []\n",
    "for i in range(1, 11):\n",
    "    KM = KMeans(n_clusters = i, max_iter = 1500)\n",
    "    KM.fit(data_for_clustering)\n",
    "    cost.append(KM.inertia_)    \n",
    "    \n",
    "# plot the cost against K values\n",
    "plt.plot(range(1, 11), cost, color ='g', linewidth ='3')\n",
    "plt.xlabel(\"Value of K\")\n",
    "plt.ylabel(\"Squared Error (Cost)\")\n",
    "plt.show() # clear the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will add an additional feature - the distance to the center of the cluster\n",
    "## used distances: euclidean, manhattan, chebyshev\n",
    "\n",
    "kmeans = KMeans(n_clusters = 3, max_iter = 1500)\n",
    "identified_clusters = kmeans.fit_predict(data_for_clustering)\n",
    "## prod\n",
    "identified_clusters_prod = kmeans.predict(data_for_clustering_prod[data_for_clustering.columns])\n",
    "\n",
    "##\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "scaler_euclidean = MinMaxScaler()\n",
    "euclidean = cdist(data_for_clustering.values, cluster_centers, 'euclidean')\n",
    "euclidean = scaler_euclidean.fit_transform(euclidean)\n",
    "## prod\n",
    "euclidean_prod = cdist(data_for_clustering_prod[data_for_clustering.columns].values, cluster_centers, 'euclidean')\n",
    "euclidean_prod = scaler_euclidean.transform(euclidean_prod)\n",
    "\n",
    "##\n",
    "scaler_manhattan = MinMaxScaler()\n",
    "manhattan = cdist(data_for_clustering.values, cluster_centers, 'cityblock')\n",
    "manhattan = scaler_manhattan.fit_transform(manhattan)\n",
    "## prod\n",
    "manhattan_prod = cdist(data_for_clustering_prod[data_for_clustering.columns].values, cluster_centers, 'cityblock')\n",
    "manhattan_prod = scaler_manhattan.transform(manhattan_prod)\n",
    "\n",
    "##\n",
    "scaler_chebyshev = MinMaxScaler()\n",
    "chebyshev = cdist(data_for_clustering.values, cluster_centers, 'chebyshev')\n",
    "chebyshev = scaler_chebyshev.fit_transform(chebyshev)\n",
    "## prod\n",
    "chebyshev_prod = cdist(data_for_clustering_prod[data_for_clustering.columns].values, cluster_centers, 'chebyshev')\n",
    "chebyshev_prod = scaler_chebyshev.transform(chebyshev_prod)\n",
    "\n",
    "## \n",
    "df_train[['euclidean_1', 'euclidean_2', 'euclidean_3']] = euclidean\n",
    "df_train[['manhattan_1', 'manhattan_2', 'manhattan_3']] = manhattan\n",
    "df_train[['chebyshev_1', 'chebyshev_2', 'chebyshev_3']] = chebyshev\n",
    "##\n",
    "df_prod[['euclidean_1', 'euclidean_2', 'euclidean_3']] = euclidean_prod\n",
    "df_prod[['manhattan_1', 'manhattan_2', 'manhattan_3']] = manhattan_prod\n",
    "df_prod[['chebyshev_1', 'chebyshev_2', 'chebyshev_3']] = chebyshev_prod\n",
    "##\n",
    "clustering_cols = ['euclidean_1', 'euclidean_2', 'euclidean_3', 'manhattan_1', 'manhattan_2', 'manhattan_3', 'chebyshev_1', 'chebyshev_2', 'chebyshev_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/168 [00:00<?, ?it/s]/root/anaconda3/envs/Summarization_Trainer/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/root/anaconda3/envs/Summarization_Trainer/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "100%|██████████| 168/168 [12:57<00:00,  4.63s/it] \n"
     ]
    }
   ],
   "source": [
    "## Split -> Encode\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(df_train, Y, stratify=Y, train_size=0.75, random_state=27)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val, Y_val, stratify=Y_val, train_size=0.75, random_state=27)\n",
    "###\n",
    "col__labelEncoder = {}\n",
    "for col in tqdm(categorical_cols_transaction + categorical_cols_identity):\n",
    "    X_train[col] = X_train[col].astype(str)\n",
    "    X_val[col] = X_val[col].astype(str)\n",
    "    X_test[col] = X_test[col].astype(str)\n",
    "    df_prod[col] = df_prod[col].astype(str)\n",
    "    ###\n",
    "    le = LabelEncoder()\n",
    "    le.fit(X_train[col].values)\n",
    "    le.classes_ = np.append(le.classes_, '<unknown>')\n",
    "    X_train[col] = le.transform(X_train[col])\n",
    "    ## if there are unknown labels -> unknown category\n",
    "    X_val[col] = X_val[col].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
    "    X_val[col] = le.transform(X_val[col])\n",
    "    ## test\n",
    "    X_test[col] = X_test[col].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
    "    X_test[col] = le.transform(X_test[col])\n",
    "    ## prod\n",
    "    df_prod[col] = df_prod[col].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
    "    df_prod[col] = le.transform(df_prod[col])\n",
    "    col__labelEncoder[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train -> train_main, train_stacking\n",
    "## 15% for val_stacking\n",
    "X_train, X_train_stacking, Y_train, Y_train_stacking = train_test_split(X_train, Y_train, stratify=Y_train, train_size=0.75, random_state=27)\n",
    "X_train_stacking, X_val_stacking, Y_train_stacking, Y_val_stacking = train_test_split(X_train_stacking, Y_train_stacking, stratify=Y_train_stacking, train_size=0.85, random_state=27)\n",
    "X_stacking_train_over, Y_stacking_train_over = RandomOverSampler(random_state=0).fit_resample(X_train_stacking, Y_train_stacking) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/Summarization_Trainer/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:19:40] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94     14655\n",
      "           1       0.63      0.19      0.29      1955\n",
      "\n",
      "    accuracy                           0.89     16610\n",
      "   macro avg       0.76      0.59      0.61     16610\n",
      "weighted avg       0.87      0.89      0.86     16610\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/Summarization_Trainer/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:20:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     16383\n",
      "           1       0.29      0.75      0.42       227\n",
      "\n",
      "    accuracy                           0.97     16610\n",
      "   macro avg       0.64      0.86      0.70     16610\n",
      "weighted avg       0.99      0.97      0.98     16610\n",
      "\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.74144 | val_0_auc: 0.78221 |  0:00:07s\n",
      "epoch 1  | loss: 0.44904 | val_0_auc: 0.81451 |  0:00:15s\n",
      "epoch 2  | loss: 0.39688 | val_0_auc: 0.83186 |  0:00:22s\n",
      "epoch 3  | loss: 0.33486 | val_0_auc: 0.85734 |  0:00:29s\n",
      "epoch 4  | loss: 0.28174 | val_0_auc: 0.83291 |  0:00:37s\n",
      "epoch 5  | loss: 0.23735 | val_0_auc: 0.80662 |  0:00:44s\n",
      "epoch 6  | loss: 0.20869 | val_0_auc: 0.84304 |  0:00:52s\n",
      "epoch 7  | loss: 0.1718  | val_0_auc: 0.85186 |  0:00:59s\n",
      "epoch 8  | loss: 0.14536 | val_0_auc: 0.84273 |  0:01:07s\n",
      "epoch 9  | loss: 0.12509 | val_0_auc: 0.84367 |  0:01:14s\n",
      "epoch 10 | loss: 0.10757 | val_0_auc: 0.84452 |  0:01:22s\n",
      "epoch 11 | loss: 0.09361 | val_0_auc: 0.85291 |  0:01:30s\n",
      "epoch 12 | loss: 0.09096 | val_0_auc: 0.85    |  0:01:37s\n",
      "epoch 13 | loss: 0.08225 | val_0_auc: 0.84797 |  0:01:45s\n",
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.85734\n",
      "Best weights from best epoch are automatically used!\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.90     13509\n",
      "           1       0.74      0.14      0.23      3101\n",
      "\n",
      "    accuracy                           0.83     16610\n",
      "   macro avg       0.79      0.56      0.57     16610\n",
      "weighted avg       0.82      0.83      0.78     16610\n",
      "\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.6596  | val_0_auc: 0.80448 |  0:00:07s\n",
      "epoch 1  | loss: 0.4607  | val_0_auc: 0.84094 |  0:00:14s\n",
      "epoch 2  | loss: 0.41561 | val_0_auc: 0.82599 |  0:00:21s\n",
      "epoch 3  | loss: 0.36632 | val_0_auc: 0.85272 |  0:00:29s\n",
      "epoch 4  | loss: 0.31902 | val_0_auc: 0.85444 |  0:00:36s\n",
      "epoch 5  | loss: 0.26497 | val_0_auc: 0.84885 |  0:00:44s\n",
      "epoch 6  | loss: 0.2163  | val_0_auc: 0.85579 |  0:00:51s\n",
      "epoch 7  | loss: 0.17684 | val_0_auc: 0.86008 |  0:00:58s\n",
      "epoch 8  | loss: 0.15515 | val_0_auc: 0.85552 |  0:01:05s\n",
      "epoch 9  | loss: 0.13957 | val_0_auc: 0.84576 |  0:01:13s\n",
      "epoch 10 | loss: 0.11774 | val_0_auc: 0.86137 |  0:01:20s\n",
      "epoch 11 | loss: 0.10253 | val_0_auc: 0.84221 |  0:01:28s\n",
      "epoch 12 | loss: 0.09091 | val_0_auc: 0.84753 |  0:01:35s\n",
      "epoch 13 | loss: 0.09829 | val_0_auc: 0.8424  |  0:01:43s\n",
      "epoch 14 | loss: 0.11093 | val_0_auc: 0.84101 |  0:01:50s\n",
      "epoch 15 | loss: 0.09032 | val_0_auc: 0.84156 |  0:01:58s\n",
      "epoch 16 | loss: 0.10581 | val_0_auc: 0.81289 |  0:02:05s\n",
      "epoch 17 | loss: 0.07296 | val_0_auc: 0.81195 |  0:02:12s\n",
      "epoch 18 | loss: 0.0615  | val_0_auc: 0.79288 |  0:02:19s\n",
      "epoch 19 | loss: 0.06247 | val_0_auc: 0.8355  |  0:02:26s\n",
      "epoch 20 | loss: 0.04882 | val_0_auc: 0.83582 |  0:02:33s\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.86137\n",
      "Best weights from best epoch are automatically used!\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96     15141\n",
      "           1       0.59      0.23      0.33      1469\n",
      "\n",
      "    accuracy                           0.92     16610\n",
      "   macro avg       0.76      0.61      0.64     16610\n",
      "weighted avg       0.90      0.92      0.90     16610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_oversampled = XGBClassifier(eta=0.001, max_depth=12, tree_method='approx') # 'approx'\n",
    "xgb_oversampled.fit(X_stacking_train_over, Y_stacking_train_over)\n",
    "preds = xgb_oversampled.predict(X_val_stacking.values)\n",
    "print(classification_report(preds, Y_val_stacking))\n",
    "\n",
    "##\n",
    "xgb_standard = XGBClassifier(eta=0.001, max_depth=9, tree_method='approx') # 'approx'\n",
    "xgb_standard.fit(X_train_stacking, Y_train_stacking)\n",
    "preds = xgb_standard.predict(X_val_stacking.values)\n",
    "print(classification_report(preds, Y_val_stacking))\n",
    "\n",
    "##\n",
    "tab_net_classifier_1 = TabNetClassifier(n_d=512, n_a=512)\n",
    "tab_net_classifier_1.fit(\n",
    "  X_stacking_train_over.values, Y_stacking_train_over.values,\n",
    "  eval_set=[(X_val_stacking.values, Y_val_stacking.values)], max_epochs=100\n",
    ")\n",
    "preds = tab_net_classifier_1.predict(X_val_stacking.values)\n",
    "print(classification_report(preds, Y_val_stacking))\n",
    "\n",
    "##\n",
    "tab_net_classifier_2 = TabNetClassifier(n_d=256, n_a=256)\n",
    "tab_net_classifier_2.fit(\n",
    "  X_stacking_train_over.values, Y_stacking_train_over.values,\n",
    "  eval_set=[(X_val_stacking.values, Y_val_stacking.values)], max_epochs=100\n",
    ")\n",
    "preds = tab_net_classifier_2.predict(X_val_stacking.values)\n",
    "print(classification_report(preds, Y_val_stacking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba_from_models(model, data):\n",
    "    return model.predict_proba(data)[:, 1]\n",
    "\n",
    "train_probas = []\n",
    "for idx, model in enumerate([xgb_oversampled, xgb_standard, tab_net_classifier_1, tab_net_classifier_2]):\n",
    "    probas_list = predict_proba_from_models(model, X_train.values)\n",
    "    train_probas.append(probas_list)\n",
    "\n",
    "val_probas = []\n",
    "for idx, model in enumerate([xgb_oversampled, xgb_standard, tab_net_classifier_1, tab_net_classifier_2]):\n",
    "    probas_list = predict_proba_from_models(model, X_val.values)\n",
    "    val_probas.append(probas_list)\n",
    "\n",
    "test_probas = []\n",
    "for idx, model in enumerate([xgb_oversampled, xgb_standard, tab_net_classifier_1, tab_net_classifier_2]):\n",
    "    probas_list = predict_proba_from_models(model, X_test.values)\n",
    "    test_probas.append(probas_list)\n",
    "\n",
    "prod_probas = []\n",
    "for idx, model in enumerate([xgb_oversampled, xgb_standard, tab_net_classifier_1, tab_net_classifier_2]):\n",
    "    probas_list = predict_proba_from_models(model, df_prod[df_train.columns].values)\n",
    "    prod_probas.append(probas_list)\n",
    "\n",
    "for idx, probas_lst in enumerate(train_probas):\n",
    "    X_train['predict_proba_from_model__' + str(idx)] = probas_lst\n",
    "    \n",
    "for idx, probas_lst in enumerate(val_probas):\n",
    "    X_val['predict_proba_from_model__' + str(idx)] = probas_lst\n",
    "    \n",
    "for idx, probas_lst in enumerate(test_probas):\n",
    "    X_test['predict_proba_from_model__' + str(idx)] = probas_lst\n",
    "    \n",
    "for idx, probas_lst in enumerate(prod_probas):\n",
    "    df_prod['predict_proba_from_model__' + str(idx)] = probas_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical column indexes, numeric column indices\n",
    "MAX_EMBEDDING_DIM = 100\n",
    "cat_dim = [int(df_train[col].nunique()) + 1 for col in categorical_cols_transaction + categorical_cols_identity] ## I add +1 because in prod there are unknown labels\n",
    "cat_dim = [[x, min(MAX_EMBEDDING_DIM, (x + 1) // 2)] for x in cat_dim]\n",
    "for el in cat_dim:\n",
    "    if el[0] < 10:\n",
    "        el[1] = el[0]\n",
    "###\n",
    "cat_cols_idx, cont_cols_idx = list(), list()\n",
    "for idx, column in enumerate(X_train.columns):\n",
    "    if column in categorical_cols_transaction + categorical_cols_identity:\n",
    "        cat_cols_idx.append(idx)\n",
    "    else:\n",
    "        cont_cols_idx.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = __Dataset(X_train.values, targets=Y_train.values, is_train=True, cat_cols_idx=cat_cols_idx, cont_cols_idx=cont_cols_idx)\n",
    "val_dataset = __Dataset(X_val.values, targets=Y_val.values, is_train=True, cat_cols_idx=cat_cols_idx, cont_cols_idx=cont_cols_idx)\n",
    "test_dataset = __Dataset(X_test.values, targets=Y_test.values, is_train=True, cat_cols_idx=cat_cols_idx, cont_cols_idx=cont_cols_idx)\n",
    "train__weighted_random_sampler = init__weighted_random__sampler(Y_train) ## we will use this sampler for balancing\n",
    "\n",
    "train_dl = DataLoader(train_dataset,\n",
    "                      sampler=train__weighted_random_sampler,\n",
    "                      batch_size=2048,\n",
    "                      num_workers=20)\n",
    "val_dl = DataLoader(val_dataset,\n",
    "                      shuffle=False,\n",
    "                      batch_size=2048,\n",
    "                      num_workers=20)\n",
    "test_dl = DataLoader(test_dataset,\n",
    "                      shuffle=False,\n",
    "                      batch_size=2048,\n",
    "                      num_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/Summarization_Trainer/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:282: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  f\"Passing `Trainer(accelerator={self.distributed_backend!r})` has been deprecated\"\n",
      "/root/anaconda3/envs/Summarization_Trainer/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:143: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  f\"Setting `Trainer(checkpoint_callback={checkpoint_callback})` is deprecated in v1.5 and will \"\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name      | Type                 | Params\n",
      "---------------------------------------------------\n",
      "0 | model     | ClassificationEmbdNN | 3.0 M \n",
      "1 | criterion | BCEWithLogitsLoss    | 0     \n",
      "---------------------------------------------------\n",
      "3.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.0 M     Total params\n",
      "12.167    Total estimated model params size (MB)\n",
      "/root/anaconda3/envs/Summarization_Trainer/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:609: UserWarning: Checkpoint directory /home/ml/Kulnevich/Kaggle/IEEE-CIS Fraud Detection/models/new_models_with_top_3k exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b58ca54abb2454aafb5547cf11de4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     8: reducing learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    15: reducing learning rate of group 0 to 2.5000e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    17: reducing learning rate of group 0 to 1.2500e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks, checkpoint_callback = get_callbacks()\n",
    "model = Simple_Trainer(cat_dim,\n",
    "                       X_train.columns[cont_cols_idx].values.tolist(),\n",
    "                       learning_rate=1e-4\n",
    "                      )\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "        gpus=[0, 1],\n",
    "        accelerator='dp',\n",
    "        callbacks=[callbacks, checkpoint_callback],\n",
    "        gradient_clip_val=0.2,\n",
    "        precision=32,  # 32 for reproducibility, 16 for test\n",
    "        auto_lr_find=True,\n",
    "        max_epochs=100,\n",
    "        checkpoint_callback=True)\n",
    "trainer.fit(model, train_dl, val_dl)\n",
    "##\n",
    "checkpoint = torch.load(checkpoint_callback.best_model_path, map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:03<00:00, 17.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# inference part\n",
    "model.eval()\n",
    "model.to('cpu')\n",
    "yhats = []\n",
    "real = []\n",
    "x_test = []\n",
    "for batch in tqdm(val_dl):\n",
    "    x, y = batch['data'], batch['target']\n",
    "    x_test.extend(x)\n",
    "    y = y.unsqueeze(1)\n",
    "    yhat = model(x)\n",
    "    yhats.extend(yhat.flatten().tolist())\n",
    "    real.extend(y.flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:  0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00    106852\n",
      "           1       0.03      1.00      0.07      3874\n",
      "\n",
      "    accuracy                           0.03    110726\n",
      "   macro avg       0.02      0.50      0.03    110726\n",
      "weighted avg       0.00      0.03      0.00    110726\n",
      "\n",
      "\n",
      "threshold:  0.010101010101010102\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93    106852\n",
      "           1       0.20      0.83      0.32      3874\n",
      "\n",
      "    accuracy                           0.88    110726\n",
      "   macro avg       0.59      0.85      0.62    110726\n",
      "weighted avg       0.97      0.88      0.91    110726\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/Summarization_Trainer/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/Summarization_Trainer/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/Summarization_Trainer/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:  0.020202020202020204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94    106852\n",
      "           1       0.22      0.81      0.34      3874\n",
      "\n",
      "    accuracy                           0.89    110726\n",
      "   macro avg       0.60      0.85      0.64    110726\n",
      "weighted avg       0.97      0.89      0.92    110726\n",
      "\n",
      "\n",
      "threshold:  0.030303030303030304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.95    106852\n",
      "           1       0.23      0.80      0.36      3874\n",
      "\n",
      "    accuracy                           0.90    110726\n",
      "   macro avg       0.61      0.85      0.65    110726\n",
      "weighted avg       0.97      0.90      0.93    110726\n",
      "\n",
      "\n",
      "threshold:  0.04040404040404041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95    106852\n",
      "           1       0.24      0.79      0.37      3874\n",
      "\n",
      "    accuracy                           0.91    110726\n",
      "   macro avg       0.62      0.85      0.66    110726\n",
      "weighted avg       0.97      0.91      0.93    110726\n",
      "\n",
      "\n",
      "threshold:  0.05050505050505051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95    106852\n",
      "           1       0.25      0.79      0.38      3874\n",
      "\n",
      "    accuracy                           0.91    110726\n",
      "   macro avg       0.62      0.85      0.66    110726\n",
      "weighted avg       0.97      0.91      0.93    110726\n",
      "\n",
      "\n",
      "threshold:  0.06060606060606061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95    106852\n",
      "           1       0.26      0.78      0.39      3874\n",
      "\n",
      "    accuracy                           0.91    110726\n",
      "   macro avg       0.62      0.85      0.67    110726\n",
      "weighted avg       0.97      0.91      0.93    110726\n",
      "\n",
      "\n",
      "threshold:  0.07070707070707072\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95    106852\n",
      "           1       0.26      0.78      0.39      3874\n",
      "\n",
      "    accuracy                           0.92    110726\n",
      "   macro avg       0.63      0.85      0.67    110726\n",
      "weighted avg       0.97      0.92      0.93    110726\n",
      "\n",
      "\n",
      "threshold:  0.08080808080808081\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96    106852\n",
      "           1       0.27      0.77      0.40      3874\n",
      "\n",
      "    accuracy                           0.92    110726\n",
      "   macro avg       0.63      0.85      0.68    110726\n",
      "weighted avg       0.97      0.92      0.94    110726\n",
      "\n",
      "\n",
      "threshold:  0.09090909090909091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96    106852\n",
      "           1       0.27      0.77      0.40      3874\n",
      "\n",
      "    accuracy                           0.92    110726\n",
      "   macro avg       0.63      0.85      0.68    110726\n",
      "weighted avg       0.97      0.92      0.94    110726\n",
      "\n",
      "\n",
      "threshold:  0.10101010101010102\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96    106852\n",
      "           1       0.28      0.77      0.41      3874\n",
      "\n",
      "    accuracy                           0.92    110726\n",
      "   macro avg       0.63      0.85      0.68    110726\n",
      "weighted avg       0.97      0.92      0.94    110726\n",
      "\n",
      "\n",
      "threshold:  0.11111111111111112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96    106852\n",
      "           1       0.28      0.77      0.41      3874\n",
      "\n",
      "    accuracy                           0.92    110726\n",
      "   macro avg       0.64      0.85      0.68    110726\n",
      "weighted avg       0.97      0.92      0.94    110726\n",
      "\n",
      "\n",
      "threshold:  0.12121212121212122\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96    106852\n",
      "           1       0.28      0.77      0.41      3874\n",
      "\n",
      "    accuracy                           0.92    110726\n",
      "   macro avg       0.64      0.85      0.69    110726\n",
      "weighted avg       0.97      0.92      0.94    110726\n",
      "\n",
      "\n",
      "threshold:  0.13131313131313133\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96    106852\n",
      "           1       0.29      0.76      0.42      3874\n",
      "\n",
      "    accuracy                           0.93    110726\n",
      "   macro avg       0.64      0.85      0.69    110726\n",
      "weighted avg       0.97      0.93      0.94    110726\n",
      "\n",
      "\n",
      "threshold:  0.14141414141414144\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96    106852\n",
      "           1       0.29      0.76      0.42      3874\n",
      "\n",
      "    accuracy                           0.93    110726\n",
      "   macro avg       0.64      0.85      0.69    110726\n",
      "weighted avg       0.97      0.93      0.94    110726\n",
      "\n",
      "\n",
      "threshold:  0.15151515151515152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96    106852\n",
      "           1       0.29      0.76      0.42      3874\n",
      "\n",
      "    accuracy                           0.93    110726\n",
      "   macro avg       0.64      0.85      0.69    110726\n",
      "weighted avg       0.97      0.93      0.94    110726\n",
      "\n",
      "\n",
      "threshold:  0.16161616161616163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96    106852\n",
      "           1       0.29      0.76      0.42      3874\n",
      "\n",
      "    accuracy                           0.93    110726\n",
      "   macro avg       0.64      0.85      0.69    110726\n",
      "weighted avg       0.97      0.93      0.94    110726\n",
      "\n",
      "\n",
      "threshold:  0.17171717171717174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96    106852\n",
      "           1       0.30      0.75      0.43      3874\n",
      "\n",
      "    accuracy                           0.93    110726\n",
      "   macro avg       0.64      0.84      0.69    110726\n",
      "weighted avg       0.97      0.93      0.94    110726\n",
      "\n",
      "\n",
      "threshold:  0.18181818181818182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96    106852\n",
      "           1       0.30      0.75      0.43      3874\n",
      "\n",
      "    accuracy                           0.93    110726\n",
      "   macro avg       0.65      0.84      0.70    110726\n",
      "weighted avg       0.97      0.93      0.94    110726\n",
      "\n",
      "\n",
      "threshold:  0.19191919191919193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96    106852\n",
      "           1       0.30      0.75      0.43      3874\n",
      "\n",
      "    accuracy                           0.93    110726\n",
      "   macro avg       0.65      0.84      0.70    110726\n",
      "weighted avg       0.97      0.93      0.94    110726\n",
      "\n",
      "\n",
      "threshold:  0.20202020202020204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96    106852\n",
      "           1       0.30      0.75      0.43      3874\n",
      "\n",
      "    accuracy                           0.93    110726\n",
      "   macro avg       0.65      0.84      0.70    110726\n",
      "weighted avg       0.97      0.93      0.94    110726\n",
      "\n",
      "\n",
      "threshold:  0.21212121212121213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96    106852\n",
      "           1       0.31      0.75      0.44      3874\n",
      "\n",
      "    accuracy                           0.93    110726\n",
      "   macro avg       0.65      0.84      0.70    110726\n",
      "weighted avg       0.97      0.93      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.22222222222222224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96    106852\n",
      "           1       0.31      0.75      0.44      3874\n",
      "\n",
      "    accuracy                           0.93    110726\n",
      "   macro avg       0.65      0.84      0.70    110726\n",
      "weighted avg       0.97      0.93      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.23232323232323235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96    106852\n",
      "           1       0.31      0.75      0.44      3874\n",
      "\n",
      "    accuracy                           0.93    110726\n",
      "   macro avg       0.65      0.84      0.70    110726\n",
      "weighted avg       0.97      0.93      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.24242424242424243\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97    106852\n",
      "           1       0.31      0.75      0.44      3874\n",
      "\n",
      "    accuracy                           0.93    110726\n",
      "   macro avg       0.65      0.84      0.70    110726\n",
      "weighted avg       0.97      0.93      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.25252525252525254\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97    106852\n",
      "           1       0.32      0.74      0.44      3874\n",
      "\n",
      "    accuracy                           0.93    110726\n",
      "   macro avg       0.65      0.84      0.70    110726\n",
      "weighted avg       0.97      0.93      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.26262626262626265\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97    106852\n",
      "           1       0.32      0.74      0.45      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.65      0.84      0.71    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.27272727272727276\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97    106852\n",
      "           1       0.32      0.74      0.45      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.65      0.84      0.71    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.2828282828282829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97    106852\n",
      "           1       0.32      0.74      0.45      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.66      0.84      0.71    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.29292929292929293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97    106852\n",
      "           1       0.32      0.74      0.45      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.66      0.84      0.71    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.30303030303030304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97    106852\n",
      "           1       0.33      0.74      0.45      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.66      0.84      0.71    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.31313131313131315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.33      0.74      0.45      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.66      0.84      0.71    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.32323232323232326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.33      0.74      0.46      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.66      0.84      0.71    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.33333333333333337\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.33      0.73      0.46      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.66      0.84      0.71    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.3434343434343435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.33      0.73      0.46      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.66      0.84      0.71    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.3535353535353536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.33      0.73      0.46      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.66      0.84      0.71    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.36363636363636365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.34      0.73      0.46      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.66      0.84      0.71    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.37373737373737376\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.34      0.73      0.46      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.66      0.84      0.72    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.38383838383838387\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.34      0.73      0.46      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.66      0.84      0.72    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.393939393939394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.34      0.73      0.47      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.67      0.84      0.72    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.4040404040404041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.34      0.73      0.47      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.67      0.84      0.72    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.4141414141414142\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.35      0.73      0.47      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.67      0.84      0.72    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.42424242424242425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.35      0.73      0.47      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.67      0.84      0.72    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.43434343434343436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.35      0.73      0.47      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.67      0.84      0.72    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.4444444444444445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.35      0.72      0.47      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.67      0.84      0.72    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.4545454545454546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.35      0.72      0.47      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.67      0.84      0.72    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.4646464646464647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.35      0.72      0.47      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.67      0.84      0.72    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.4747474747474748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.35      0.72      0.48      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.67      0.84      0.72    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.48484848484848486\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.36      0.72      0.48      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.67      0.84      0.72    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.494949494949495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.36      0.72      0.48      3874\n",
      "\n",
      "    accuracy                           0.94    110726\n",
      "   macro avg       0.67      0.84      0.72    110726\n",
      "weighted avg       0.97      0.94      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.5050505050505051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.36      0.72      0.48      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.67      0.84      0.73    110726\n",
      "weighted avg       0.97      0.95      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.5151515151515152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.36      0.72      0.48      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.68      0.84      0.73    110726\n",
      "weighted avg       0.97      0.95      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.5252525252525253\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.36      0.72      0.48      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.68      0.84      0.73    110726\n",
      "weighted avg       0.97      0.95      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.5353535353535354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    106852\n",
      "           1       0.37      0.72      0.48      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.68      0.84      0.73    110726\n",
      "weighted avg       0.97      0.95      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.5454545454545455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97    106852\n",
      "           1       0.37      0.72      0.49      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.68      0.84      0.73    110726\n",
      "weighted avg       0.97      0.95      0.95    110726\n",
      "\n",
      "\n",
      "threshold:  0.5555555555555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97    106852\n",
      "           1       0.37      0.72      0.49      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.68      0.84      0.73    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.5656565656565657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97    106852\n",
      "           1       0.37      0.71      0.49      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.68      0.84      0.73    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.5757575757575758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97    106852\n",
      "           1       0.37      0.71      0.49      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.68      0.83      0.73    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.5858585858585859\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97    106852\n",
      "           1       0.37      0.71      0.49      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.68      0.83      0.73    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.595959595959596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97    106852\n",
      "           1       0.38      0.71      0.49      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.68      0.83      0.73    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.6060606060606061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97    106852\n",
      "           1       0.38      0.71      0.49      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.68      0.83      0.73    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.6161616161616162\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97    106852\n",
      "           1       0.38      0.71      0.49      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.68      0.83      0.73    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.6262626262626263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97    106852\n",
      "           1       0.38      0.71      0.49      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.68      0.83      0.73    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.6363636363636365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97    106852\n",
      "           1       0.38      0.71      0.50      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.69      0.83      0.73    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.6464646464646465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97    106852\n",
      "           1       0.38      0.71      0.50      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.69      0.83      0.74    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.6565656565656566\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97    106852\n",
      "           1       0.39      0.71      0.50      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.69      0.83      0.74    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.6666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97    106852\n",
      "           1       0.39      0.71      0.50      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.69      0.83      0.74    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.6767676767676768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97    106852\n",
      "           1       0.39      0.70      0.50      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.69      0.83      0.74    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.686868686868687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97    106852\n",
      "           1       0.39      0.70      0.50      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.69      0.83      0.74    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.696969696969697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97    106852\n",
      "           1       0.39      0.70      0.51      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.69      0.83      0.74    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.7070707070707072\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97    106852\n",
      "           1       0.40      0.70      0.51      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.69      0.83      0.74    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.7171717171717172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98    106852\n",
      "           1       0.40      0.70      0.51      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.69      0.83      0.74    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.7272727272727273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98    106852\n",
      "           1       0.40      0.70      0.51      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.70      0.83      0.74    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.7373737373737375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98    106852\n",
      "           1       0.40      0.70      0.51      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.70      0.83      0.74    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.7474747474747475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98    106852\n",
      "           1       0.40      0.69      0.51      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.70      0.83      0.74    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.7575757575757577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98    106852\n",
      "           1       0.41      0.69      0.51      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.70      0.83      0.74    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.7676767676767677\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98    106852\n",
      "           1       0.41      0.69      0.51      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.70      0.83      0.74    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.7777777777777778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98    106852\n",
      "           1       0.41      0.69      0.52      3874\n",
      "\n",
      "    accuracy                           0.95    110726\n",
      "   macro avg       0.70      0.83      0.75    110726\n",
      "weighted avg       0.97      0.95      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.787878787878788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98    106852\n",
      "           1       0.41      0.69      0.52      3874\n",
      "\n",
      "    accuracy                           0.96    110726\n",
      "   macro avg       0.70      0.83      0.75    110726\n",
      "weighted avg       0.97      0.96      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.797979797979798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    106852\n",
      "           1       0.42      0.69      0.52      3874\n",
      "\n",
      "    accuracy                           0.96    110726\n",
      "   macro avg       0.70      0.83      0.75    110726\n",
      "weighted avg       0.97      0.96      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.8080808080808082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    106852\n",
      "           1       0.42      0.69      0.52      3874\n",
      "\n",
      "    accuracy                           0.96    110726\n",
      "   macro avg       0.70      0.83      0.75    110726\n",
      "weighted avg       0.97      0.96      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.8181818181818182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    106852\n",
      "           1       0.42      0.68      0.52      3874\n",
      "\n",
      "    accuracy                           0.96    110726\n",
      "   macro avg       0.71      0.82      0.75    110726\n",
      "weighted avg       0.97      0.96      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.8282828282828284\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    106852\n",
      "           1       0.43      0.68      0.52      3874\n",
      "\n",
      "    accuracy                           0.96    110726\n",
      "   macro avg       0.71      0.82      0.75    110726\n",
      "weighted avg       0.97      0.96      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.8383838383838385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    106852\n",
      "           1       0.43      0.68      0.53      3874\n",
      "\n",
      "    accuracy                           0.96    110726\n",
      "   macro avg       0.71      0.82      0.75    110726\n",
      "weighted avg       0.97      0.96      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.8484848484848485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    106852\n",
      "           1       0.43      0.68      0.53      3874\n",
      "\n",
      "    accuracy                           0.96    110726\n",
      "   macro avg       0.71      0.82      0.75    110726\n",
      "weighted avg       0.97      0.96      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.8585858585858587\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    106852\n",
      "           1       0.44      0.68      0.53      3874\n",
      "\n",
      "    accuracy                           0.96    110726\n",
      "   macro avg       0.71      0.82      0.75    110726\n",
      "weighted avg       0.97      0.96      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.8686868686868687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    106852\n",
      "           1       0.44      0.67      0.53      3874\n",
      "\n",
      "    accuracy                           0.96    110726\n",
      "   macro avg       0.71      0.82      0.76    110726\n",
      "weighted avg       0.97      0.96      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.8787878787878789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    106852\n",
      "           1       0.44      0.67      0.53      3874\n",
      "\n",
      "    accuracy                           0.96    110726\n",
      "   macro avg       0.72      0.82      0.76    110726\n",
      "weighted avg       0.97      0.96      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.888888888888889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    106852\n",
      "           1       0.45      0.67      0.54      3874\n",
      "\n",
      "    accuracy                           0.96    110726\n",
      "   macro avg       0.72      0.82      0.76    110726\n",
      "weighted avg       0.97      0.96      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.8989898989898991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    106852\n",
      "           1       0.45      0.67      0.54      3874\n",
      "\n",
      "    accuracy                           0.96    110726\n",
      "   macro avg       0.72      0.82      0.76    110726\n",
      "weighted avg       0.97      0.96      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.9090909090909092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    106852\n",
      "           1       0.46      0.67      0.54      3874\n",
      "\n",
      "    accuracy                           0.96    110726\n",
      "   macro avg       0.72      0.82      0.76    110726\n",
      "weighted avg       0.97      0.96      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.9191919191919192\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    106852\n",
      "           1       0.46      0.66      0.55      3874\n",
      "\n",
      "    accuracy                           0.96    110726\n",
      "   macro avg       0.73      0.82      0.76    110726\n",
      "weighted avg       0.97      0.96      0.96    110726\n",
      "\n",
      "\n",
      "threshold:  0.9292929292929294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    106852\n",
      "           1       0.47      0.66      0.55      3874\n",
      "\n",
      "    accuracy                           0.96    110726\n",
      "   macro avg       0.73      0.81      0.76    110726\n",
      "weighted avg       0.97      0.96      0.97    110726\n",
      "\n",
      "\n",
      "threshold:  0.9393939393939394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    106852\n",
      "           1       0.48      0.65      0.55      3874\n",
      "\n",
      "    accuracy                           0.96    110726\n",
      "   macro avg       0.73      0.81      0.77    110726\n",
      "weighted avg       0.97      0.96      0.97    110726\n",
      "\n",
      "\n",
      "threshold:  0.9494949494949496\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98    106852\n",
      "           1       0.49      0.65      0.55      3874\n",
      "\n",
      "    accuracy                           0.96    110726\n",
      "   macro avg       0.74      0.81      0.77    110726\n",
      "weighted avg       0.97      0.96      0.97    110726\n",
      "\n",
      "\n",
      "threshold:  0.9595959595959597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98    106852\n",
      "           1       0.50      0.64      0.56      3874\n",
      "\n",
      "    accuracy                           0.96    110726\n",
      "   macro avg       0.74      0.81      0.77    110726\n",
      "weighted avg       0.97      0.96      0.97    110726\n",
      "\n",
      "\n",
      "threshold:  0.9696969696969697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98    106852\n",
      "           1       0.51      0.63      0.56      3874\n",
      "\n",
      "    accuracy                           0.97    110726\n",
      "   macro avg       0.75      0.80      0.77    110726\n",
      "weighted avg       0.97      0.97      0.97    110726\n",
      "\n",
      "\n",
      "threshold:  0.9797979797979799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98    106852\n",
      "           1       0.53      0.62      0.57      3874\n",
      "\n",
      "    accuracy                           0.97    110726\n",
      "   macro avg       0.76      0.80      0.78    110726\n",
      "weighted avg       0.97      0.97      0.97    110726\n",
      "\n",
      "\n",
      "threshold:  0.98989898989899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98    106852\n",
      "           1       0.56      0.60      0.58      3874\n",
      "\n",
      "    accuracy                           0.97    110726\n",
      "   macro avg       0.77      0.79      0.78    110726\n",
      "weighted avg       0.97      0.97      0.97    110726\n",
      "\n",
      "\n",
      "threshold:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98    106852\n",
      "           1       0.00      0.00      0.00      3874\n",
      "\n",
      "    accuracy                           0.97    110726\n",
      "   macro avg       0.48      0.50      0.49    110726\n",
      "weighted avg       0.93      0.97      0.95    110726\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/Summarization_Trainer/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/Summarization_Trainer/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/Summarization_Trainer/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for thresh in np.linspace(0,1,100):\n",
    "    yhats_after_thresh = [1 if x > thresh else 0 for x in yhats]\n",
    "    print('threshold: ', thresh)\n",
    "    print(classification_report(real, yhats_after_thresh))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_dataset = __Dataset(df_prod[X_train.columns].values, targets=None, is_train=False, cat_cols_idx=cat_cols_idx, cont_cols_idx=cont_cols_idx)\n",
    "test_dl = DataLoader(prod_dataset,\n",
    "                      shuffle=False,\n",
    "                      batch_size=512,\n",
    "                      num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36909, 259)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhats_prod = []\n",
    "for batch in test_dl:\n",
    "    x = batch['data'] \n",
    "    yhat = model(x)\n",
    "    yhats_prod.extend(yhat.flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({\n",
    "    'TransactionID': df_prod['TransactionID'].values.tolist(),\n",
    "    'isFraud': yhats_prod\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv('my_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Summarization_Trainer",
   "language": "python",
   "name": "summarization_trainer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
